{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Medidas para verificar grupos.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPCBQkzX+I50Ghe944aS/TT"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"V8vpbYZfWiTj"},"source":["# Medidas de Grupo entre Clusteres\r\n","Adjusted Mutual Information between two clusterings."]},{"cell_type":"code","metadata":{"id":"YkiAEuHMhhCk"},"source":["import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6SAwn6ED32xU"},"source":["# verificar grupos de clusteres\r\n","ce = []\r\n","## Giga\r\n","# Resting state\r\n","# group1_5 = np.asarray([1, 2, 0, 1, 1, 1, 2, 2, 2, 1, 0, 1, 1, 1, 1, 2, 2, 2, 2, 0, 0, 0,\r\n","#        1, 2, 1, 1, 2, 0, 0, 0, 2, 2, 1, 0, 0, 2, 0, 2, 1, 2, 1, 0, 2, 1,\r\n","#        0, 1, 1, 1, 2, 0])+1\r\n","\r\n","# # MI\r\n","# group2   = np.asarray([0, 2, 0, 1, 1, 1, 2, 2, 2, 1, 0, 2, 1, 1, 1, 2, 2, 0, 2, 0, 0, 0,\r\n","#        1, 0, 1, 1, 2, 0, 0, 0, 2, 2, 1, 0, 1, 2, 0, 2, 1, 2, 1, 0, 2, 1,\r\n","#        0, 1, 1, 0, 2, 0])+1\r\n","\r\n","## physionet\r\n","# Resting-state\r\n","group1_5 = np.asarray([0, 1, 2, 2, 0, 0, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 0, 1, 1,\r\n","       2, 0, 2, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 2, 0, 2, 1, 2, 1, 1, 2,\r\n","       2, 1, 0, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 2, 2, 1, 0, 2, 2,\r\n","       2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 0, 1, 2, 2, 2, 1, 1, 2, 0, 2,\r\n","       0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 2, 2, 1, 1])+1\r\n","    # [0, 1, 2, 2, 0, 0, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 1, 1, 1, 0, 1, 1,\r\n","    #    2, 0, 2, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 2, 0, 2, 1, 2, 1, 1, 2,\r\n","    #    2, 1, 0, 1, 2, 1, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 2, 2, 1, 0, 2, 2,\r\n","    #    2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 0, 1, 2, 2, 2, 1, 1, 2, 0, 2,\r\n","    #    0, 1, 1, 1, 1, 2, 2, 0, 2, 0, 2, 0, 1, 2, 2, 1, 2])+1\r\n","\r\n","# MI\r\n","group2   = np.asarray([0, 1, 0, 0, 0, 0, 1, 2, 2, 2, 2, 1, 0, 0, 1, 0, 0, 2, 1, 0, 2, 0,\r\n","       0, 0, 2, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 2, 1,\r\n","       0, 0, 0, 1, 0, 2, 0, 0, 0, 1, 2, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2,\r\n","       2, 0, 2, 1, 2, 1, 1, 1, 1, 0, 2, 2, 0, 2, 0, 0, 2, 1, 1, 0, 0, 0,\r\n","       0, 2, 1, 1, 2, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1, 2])+1\r\n","    \r\n","    # [1, 0, 1, 1, 1, 1, 0, 2, 2, 2, 2, 0, 1, 1, 0, 1, 1, 2, 0, 1, 2, 2,\r\n","    #    1, 1, 2, 1, 2, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 2, 0,\r\n","    #    1, 1, 1, 0, 1, 2, 1, 1, 1, 0, 2, 0, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2,\r\n","    #    1, 2, 2, 2, 2, 0, 0, 0, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 0, 2, 2, 1,\r\n","    #    1, 2, 0, 0, 2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 0, 2])+1\r\n","\r\n","group1_5s = np.zeros(np.shape(group1_5))#np.copy(group1_5)\r\n","for cl in np.unique(group2):\r\n","   tmp = group1_5[group2==cl]\r\n","   counts_elements = np.zeros((len(np.unique(group2)),1))\r\n","   for ii in range(len(np.unique(group2))):\r\n","       counts_elements[ii] = np.sum(tmp==(ii+1))\r\n","   ce.append(counts_elements)\r\n","ce=np.asarray(ce).squeeze()\r\n","for i in range(len(ce)):\r\n","   print(ce)\r\n","   inx = np.argmax(ce.max(1))\r\n","   clas=np.argmax(ce[inx,:])\r\n","   print(clas)\r\n","   group1_5s[group1_5==(inx+1)] = clas+1\r\n","   ce[inx,:]=0\r\n","   ce[:,clas]=0\r\n","# group1_5=group1_5s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sKVJypPjpVof"},"source":["group1_5s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"o2W2QBX4pdWE"},"source":["group1_5"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yt0JTPUOkXoP"},"source":["ce=np.asarray(ce).squeeze()\r\n","ce"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bzy5z3VkWqZf"},"source":["from sklearn.metrics.cluster import adjusted_mutual_info_score\r\n","Cluster_MI   = group2\r\n","Cluster_rest = group1_5s\r\n","adjusted_mutual_info_score(Cluster_MI, Cluster_rest)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H4cjqqNDXk4Q"},"source":["Rand index adjusted for chance."]},{"cell_type":"code","metadata":{"id":"oMvXQ9IJXquw"},"source":["from sklearn.metrics.cluster import adjusted_rand_score\r\n","Cluster_MI   = group2\r\n","Cluster_rest = group1_5s\r\n","adjusted_rand_score(Cluster_MI, Cluster_rest)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xRcKfYkzX1Gd"},"source":["Homogeneity metric of a cluster labeling given a ground truth."]},{"cell_type":"code","metadata":{"id":"U-et6en2X7pu"},"source":["from sklearn.metrics.cluster import homogeneity_score\r\n","Cluster_MI   = group2\r\n","Cluster_rest = group1_5s\r\n","homogeneity_score(Cluster_MI, Cluster_rest)"],"execution_count":null,"outputs":[]}]}